{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4151360-45f0-4044-86e0-7a60ba99eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import statsmodels\n",
    "from skbio.stats.ordination import pcoa \n",
    "from scipy.spatial import distance\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pyreadr\n",
    "import warnings\n",
    "from scipy.spatial.distance import braycurtis\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from skbio.stats.ordination import pcoa \n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from skbio.stats.composition import clr\n",
    "from scipy.stats import wilcoxon\n",
    "from statsmodels.stats import multitest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07287a44-1bda-415a-9851-dd2b3c0a9e74",
   "metadata": {},
   "source": [
    "### WILCOXON PAIRED TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ff05e6-f017-4c9f-83c6-1d6507215b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_clr(df, pseudocount_vector):\n",
    "    ''' data - features as index and samples as columns '''\n",
    "    \n",
    "    df = df.div(df.sum(axis=1), axis=0)\n",
    "    data = df + pseudocount_vector.reshape(len(pseudocount_vector), 1)\n",
    "    data = data.T.copy()\n",
    "    #data += 1e-2                                  # add pseudocount\n",
    "    return pd.DataFrame(clr(data.T), columns=data.index, index=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17704fd3-69d2-415b-97c0-8776e27d6327",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def run_wilcoxon_test(i, N, sampling, transformation='clr'):\n",
    "    \n",
    "    sim_dir = \"/Users/zkarwowska/Desktop/EMBL_project/zeevi_dataset_v5/simulation/efs3/\"\n",
    "\n",
    "    counts = pyreadr.read_r(sim_dir + f\"rep{i}/counts_n{N}.rds\")[None]\n",
    "    metadata = pyreadr.read_r(sim_dir + f\"rep{i}/metadata_n{N}.rds\")[None]\n",
    "    gt_file = pd.read_csv(sim_dir + f'rep{i}/gt_features.tsv', sep='\\t')\n",
    "\n",
    "    \n",
    "    filtered_metadata = metadata[metadata['delta.t'].isin(sampling)].copy()\n",
    "    filtered_metadata['intervention'] = np.where((filtered_metadata['delta.t'] > 9) & (filtered_metadata['delta.t'] < 20), 0, 1)\n",
    "    filtered_counts = counts[filtered_metadata['sample_name']].T\n",
    "    pseudocount_vector = (filtered_counts[filtered_counts>0].min(axis=1) * 1e-1).values\n",
    "\n",
    "    if transformation == 'log_relab':\n",
    "        input_counts = np.log(filtered_counts + 1e-2)\n",
    "    elif transformation == 'clr':\n",
    "        input_counts = to_clr(filtered_counts, pseudocount_vector)\n",
    "\n",
    "    merged_df = pd.merge(input_counts, filtered_metadata.set_index('sample_name'), left_index=True, right_index=True)\n",
    "    features = filtered_counts.columns\n",
    "\n",
    "    pvalues_list = []\n",
    "    for feature in features:\n",
    "        df = merged_df[[feature, 'host_subject_id', 'delta.t', 'Group', 'intervention']]\n",
    "        df['host_subject_id_new'] = df['host_subject_id'] + ['_A', '_B', '_C', '_D'] * int(len(df)/4)\n",
    "        pivot_df = df.pivot(index='host_subject_id_new', columns='intervention', values=feature)\n",
    "\n",
    "        if pivot_df.columns.isin([1, 0]).all() and pivot_df[[1, 0]].dropna().shape[0] > 1:\n",
    "            stat, p_value = wilcoxon(pivot_df[1].dropna(), pivot_df[0].dropna(), zero_method='zsplit', alternative='two-sided')\n",
    "            pvalues_list.append({'feature': feature, 'pvalue': p_value})\n",
    "        else:\n",
    "            pvalues_list.append({'feature': feature, 'pvalue': None})\n",
    "\n",
    "    results_df = pd.DataFrame(pvalues_list)\n",
    "    results_df = pd.merge(results_df.set_index('feature'), gt_file.set_index('feature'), left_index=True, right_index=True)\n",
    "    results_df['qval'] = multitest.multipletests(results_df['pvalue'].dropna(), method='fdr_bh')[1]\n",
    "    results_df['ypred'] = np.where(results_df['qval'] < 0.05, 1, 0)\n",
    "    results_df['ytrue'] = np.abs(results_df['upregulated'])\n",
    "    tn, fp, fn, tp = confusion_matrix(results_df['ytrue'], results_df['ypred']).ravel()\n",
    "    precision = precision_score(results_df['ytrue'], results_df['ypred'], zero_division=0)\n",
    "    recall = recall_score(results_df['ytrue'], results_df['ypred'])\n",
    "\n",
    "    res = [{\n",
    "        'sample_size': N,\n",
    "        'rep': i,\n",
    "        'sampling': len(sampling),\n",
    "        'transformation': transformation,\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tp': tp,\n",
    "        'ypred':results_df['ypred'].sum(),\n",
    "        'recall': recall,\n",
    "        'precision': precision\n",
    "    }]\n",
    "    \n",
    "    results_df['FP'] = np.where((results_df.ytrue == 0) & (results_df.ypred == 1), 1, 0)\n",
    "    results_df.to_csv(f'/Users/zkarwowska/Desktop/EMBL_project/zeevi_dataset_v5/wilcoxon_all/{transformation}/wilcoxon_sampling_{N}_efs_3_rep_{i}_d_{len(sampling)}.csv')\n",
    "    \n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84d7d30-1de0-418b-b2c0-fa097598ed29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def run_wilcoxon_test(i, N, sampling, transformation='clr'):\n",
    "    \n",
    "    sim_dir = \"/Users/zkarwowska/Desktop/EMBL_project/zeevi_dataset_v5/simulation/efs3/\"\n",
    "\n",
    "    counts = pyreadr.read_r(sim_dir + f\"rep{i}/counts_n{N}.rds\")[None]\n",
    "    metadata = pyreadr.read_r(sim_dir + f\"rep{i}/metadata_n{N}.rds\")[None]\n",
    "    gt_file = pd.read_csv(sim_dir + f'rep{i}/gt_features.tsv', sep='\\t')\n",
    "\n",
    "    \n",
    "    filtered_metadata = metadata[metadata['delta.t'].isin(sampling)].copy()\n",
    "    filtered_metadata['intervention'] = np.where((filtered_metadata['delta.t'] > 9) & (filtered_metadata['delta.t'] < 20), 0, 1)\n",
    "    filtered_counts = counts[filtered_metadata['sample_name']].T\n",
    "    pseudocount_vector = (filtered_counts[filtered_counts>0].min(axis=1) * 1e-1).values\n",
    "\n",
    "    if transformation == 'log_relab':\n",
    "        input_counts = np.log(filtered_counts + 1e-2)\n",
    "    elif transformation == 'clr':\n",
    "        input_counts = to_clr(filtered_counts, pseudocount_vector)\n",
    "\n",
    "    merged_df = pd.merge(input_counts, filtered_metadata.set_index('sample_name'), left_index=True, right_index=True)\n",
    "    features = filtered_counts.columns\n",
    "\n",
    "    pvalues_list = []\n",
    "    for feature in features:\n",
    "        df = merged_df[[feature, 'host_subject_id', 'delta.t', 'Group', 'intervention']]\n",
    "        df['host_subject_id_new'] = df['host_subject_id'] + ['_A', '_B', '_C', '_D'] * int(len(df)/4)\n",
    "        pivot_df = df.pivot(index='host_subject_id_new', columns='intervention', values=feature)\n",
    "\n",
    "        if pivot_df.columns.isin([1, 0]).all() and pivot_df[[1, 0]].dropna().shape[0] > 1:\n",
    "            stat, p_value = wilcoxon(pivot_df[1].dropna(), pivot_df[0].dropna(), zero_method='zsplit', alternative='two-sided')\n",
    "            pvalues_list.append({'feature': feature, 'pvalue': p_value})\n",
    "        else:\n",
    "            pvalues_list.append({'feature': feature, 'pvalue': None})\n",
    "\n",
    "    results_df = pd.DataFrame(pvalues_list)\n",
    "    #results_df = pd.merge(results_df.set_index('feature'), gt_file.set_index('feature'), left_index=True, right_index=True)\n",
    "    #results_df.to_csv(f'/Users/zkarwowska/Desktop/EMBL_project/zeevi_dataset_v5/wilcoxon_all/{transformation}/wilcoxon_sampling_{N}_efs_3_rep_{i}_d_{len(sampling)}.csv')\n",
    "    \n",
    "    return merged_df#results_df#pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed28a025-4d50-46b8-a3fa-90f7963aff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "from scipy.stats import wilcoxon\n",
    "from pathlib import Path\n",
    "\n",
    "def process_data(i, N, sampling, transformation, sim_dir, efs):\n",
    "    # Use pathlib for path handling\n",
    "    base_path = Path(sim_dir) / f\"rep{i}\"\n",
    "    \n",
    "    # Load data more efficiently\n",
    "    counts = pyreadr.read_r(base_path / f\"counts_n{N}.rds\")[None]\n",
    "    metadata = pyreadr.read_r(base_path / f\"metadata_n{N}.rds\")[None]\n",
    "    gt_file = pd.read_csv(base_path / 'gt_features.tsv', sep='\\t')\n",
    "    \n",
    "    # Filter metadata once\n",
    "    mask = metadata['delta.t'].isin(sampling)\n",
    "    filtered_metadata = metadata[mask].copy()\n",
    "    filtered_metadata['intervention'] = ((filtered_metadata['delta.t'] > 9) & \n",
    "                                      (filtered_metadata['delta.t'] < 20)).astype(int)\n",
    "    \n",
    "    # Filter counts using boolean indexing\n",
    "    filtered_counts = counts[filtered_metadata['sample_name']].T\n",
    "    \n",
    "    # Calculate pseudocounts more efficiently\n",
    "    pseudocount_vector = filtered_counts[filtered_counts > 0].min(axis=1).values * 0.1\n",
    "    \n",
    "    # Transform data\n",
    "    if transformation == 'log_relab':\n",
    "        input_counts = np.log(filtered_counts + 0.01)\n",
    "    elif transformation == 'clr':\n",
    "        input_counts = to_clr(filtered_counts, pseudocount_vector)\n",
    "    \n",
    "    # Merge data more efficiently\n",
    "    merged_df = pd.concat([\n",
    "        input_counts,\n",
    "        filtered_metadata.set_index('sample_name')\n",
    "    ], axis=1)\n",
    "    \n",
    "    # Calculate p-values more efficiently\n",
    "    pvalues_list = []\n",
    "    features = filtered_counts.columns\n",
    "    \n",
    "    for feature in features:\n",
    "        df_subset = merged_df[[feature, 'host_subject_id']]\n",
    "        \n",
    "        # Vectorized operations instead of loops\n",
    "        result_data = []\n",
    "        for host in merged_df['host_subject_id'].unique():\n",
    "            host_data = df_subset[df_subset['host_subject_id'] == host]\n",
    "            \n",
    "            if len(sampling) == 4:  # Ensure we have enough data points\n",
    "                x1 = host_data[feature].iloc[:2].values\n",
    "                x2 = host_data[feature].iloc[2:4].values\n",
    "                result_data.append((x1, x2))\n",
    "                \n",
    "            elif len(sampling) == 2:  # Ensure we have enough data points\n",
    "                x1 = host_data[feature].iloc[:1].values\n",
    "                x2 = host_data[feature].iloc[1:2].values\n",
    "                result_data.append((x1, x2))\n",
    "            \n",
    "            elif len(sampling) == 6:  # Ensure we have enough data points\n",
    "                x1 = host_data[feature].iloc[:3].values\n",
    "                x2 = host_data[feature].iloc[3:6].values\n",
    "                result_data.append((x1, x2))\n",
    "        \n",
    "        if result_data:\n",
    "            x1_combined = np.concatenate([x[0] for x in result_data])\n",
    "            x2_combined = np.concatenate([x[1] for x in result_data])\n",
    "            \n",
    "            stat, p_value = wilcoxon(x1_combined, x2_combined, \n",
    "                                   zero_method='zsplit', \n",
    "                                   alternative='two-sided')\n",
    "            \n",
    "            pvalues_list.append({\n",
    "                'feature': feature,\n",
    "                'pvalue': p_value\n",
    "            })\n",
    "    \n",
    "    results_df = pd.DataFrame(pvalues_list)\n",
    "    results_df = pd.merge(results_df.set_index('feature'), gt_file.set_index('feature'), left_index=True, right_index=True)\n",
    "    results_df['effect_size'] = efs\n",
    "    results_df['iteration'] = i\n",
    "    results_df.to_csv(f'/Users/zkarwowska/Desktop/EMBL_project/zeevi_dataset_v5/results/wilcoxon/one_arm_all/{transformation}/wilcoxon_sampling_{N}_efs_{efs}_rep_{i}_d_{len(sampling)}.csv')\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea5d9955-141c-4261-bfb8-028d3f6a09ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_dir = \"/Users/zkarwowska/Desktop/EMBL_project/zeevi_dataset_v5/simulation/efs2/\"\n",
    "wd = '/Users/zkarwowska/Desktop/EMBL_project/zeevi_dataset_v5/results/wilcoxon/one_arm_all/'\n",
    "\n",
    "Sampling = [[2, 15], [2, 6, 15, 19], [2, 5, 8, 12, 15, 19]]\n",
    "\n",
    "Wilcoxon_results = pd.DataFrame()\n",
    "for efs in [125, 15, 2, 3, 5]:\n",
    "    sim_dir = f\"/Users/zkarwowska/new_embl_folder/zeevi_dataset_v5/simulation/efs{efs}/\"\n",
    "    for transformation in ['clr', 'log_relab']:\n",
    "            for N in [10, 20, 30, 40, 50, 60, 70, 80]:\n",
    "                for sampling in Sampling:\n",
    "                        for i in range(1, 11):\n",
    "\n",
    "                            file = f'{wd}/{transformation}/wilcoxon_sampling_{N}_efs_{efs}_rep_{i}_d_{len(sampling)}.csv'\n",
    "                            my_file = Path(file)\n",
    "                            if my_file.is_file():\n",
    "                                pass\n",
    "                            else:\n",
    "                                process_data(i, N, sampling, transformation, sim_dir, efs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff33d19-5a48-47c3-ab59-8b8ccc33def6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c34f9-472c-49e1-aeb4-50e98fd0b38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08b514-9b57-423a-8490-f89989b2fb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b789fbf-bdb0-4b89-903c-07fb07bab0a7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "Sampling = [[2, 15], [2, 6, 15, 19]]#2, 5, 8, 12, 15, 19], \n",
    "Wilcoxon_results = pd.DataFrame()\n",
    "for transformation in ['log_relab', 'clr']:\n",
    "        for N in [10, 20, 30, 40, 50, 60]:\n",
    "            for sampling in Sampling:\n",
    "                for i in range(1, 10):\n",
    "                    #try:\n",
    "                    df = run_wilcoxon_test(i, N, sampling, transformation)\n",
    "                    Wilcoxon_results = pd.concat([Wilcoxon_results, df])\n",
    "                    #except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc398363-76ac-4fe2-832c-96e1b719c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_all_samples = Wilcoxon_results.groupby(by = ['sample_size', 'transformation']).median().reset_index()\n",
    "sns.lineplot(x = DF_all_samples.sample_size, y = DF_all_samples.precision, hue = DF_all_samples.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596495e9-fbf2-47eb-adea-524a9eddabfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Wilcoxon_results[Wilcoxon_results['transformation'] == 'clr']\n",
    "\n",
    "for i in range(5):\n",
    "    df1=df[df['rep']==i]\n",
    "    sns.lineplot(data=df1, x='sample_size', y = 'precision', color='k')\n",
    "    sns.scatterplot(data=df1, x='sample_size', y = 'precision', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb11df-6be6-42d4-b0f2-c941aa562e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wilcoxon_results.to_csv('/Users/zkarwowska/Desktop/EMBL_project/zeevi_dataset_v4/wilcoxon_one_arm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd217ea-7c41-4ed2-a9d6-25aed4dbb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wilcoxon_test(i, N, sampling, transformation='clr'):\n",
    "    \n",
    "    sim_dir = \"/Users/zkarwowska/Desktop/EMBL_project/zeevi_dataset_v5/simulation/efs3/\"\n",
    "\n",
    "    counts = pyreadr.read_r(sim_dir + f\"rep{i}/counts_n{N}.rds\")[None]\n",
    "    metadata = pyreadr.read_r(sim_dir + f\"rep{i}/metadata_n{N}.rds\")[None]\n",
    "    gt_file = pd.read_csv(sim_dir + f'rep{i}/gt_features.tsv', sep='\\t')\n",
    "\n",
    "    \n",
    "    filtered_metadata = metadata[metadata['delta.t'].isin(sampling)].copy()\n",
    "    filtered_metadata['intervention'] = np.where((filtered_metadata['delta.t'] > 9) & (filtered_metadata['delta.t'] < 20), 0, 1)\n",
    "    filtered_counts = counts[filtered_metadata['sample_name']].T\n",
    "    pseudocount_vector = (filtered_counts[filtered_counts>0].min(axis=1) * 1e-1).values\n",
    "\n",
    "    if transformation == 'log_relab':\n",
    "        input_counts = np.log(filtered_counts + 1e-2)\n",
    "    elif transformation == 'clr':\n",
    "        input_counts = to_clr(filtered_counts, pseudocount_vector)\n",
    "\n",
    "    merged_df = pd.merge(input_counts, filtered_metadata.set_index('sample_name'), left_index=True, right_index=True)\n",
    "    features = filtered_counts.columns\n",
    "\n",
    "    pvalues_list = []\n",
    "    for feature in features:\n",
    "        df = merged_df[[feature, 'host_subject_id', 'delta.t', 'Group', 'intervention']]\n",
    "        grouped_df = df.groupby(['host_subject_id', 'intervention']).agg(mean=(feature, 'mean')).reset_index()\n",
    "        pivot_df = grouped_df.pivot(index='host_subject_id', columns='intervention', values='mean')\n",
    "\n",
    "        if pivot_df.columns.isin([1, 0]).all() and pivot_df[[1, 0]].dropna().shape[0] > 1:\n",
    "            stat, p_value = wilcoxon(pivot_df[1].fillna(1), pivot_df[0].fillna(1), zero_method='zsplit', alternative='two-sided')\n",
    "            pvalues_list.append({'feature': feature, 'pvalue': p_value})\n",
    "        else:\n",
    "            pvalues_list.append({'feature': feature, 'pvalue': None})\n",
    "\n",
    "    results_df = pd.DataFrame(pvalues_list)\n",
    "    results_df = pd.merge(results_df.set_index('feature'), gt_file.set_index('feature'), left_index=True, right_index=True)\n",
    "    results_df['qval'] = multitest.multipletests(results_df['pvalue'].dropna(), method='fdr_bh')[1]\n",
    "    results_df['ypred'] = np.where(results_df['qval'] < 0.05, 1, 0)\n",
    "    results_df['ytrue'] = np.abs(results_df['upregulated'])\n",
    "    tn, fp, fn, tp = confusion_matrix(results_df['ytrue'], results_df['ypred']).ravel()\n",
    "    precision = precision_score(results_df['ytrue'], results_df['ypred'], zero_division=0)\n",
    "    recall = recall_score(results_df['ytrue'], results_df['ypred'])\n",
    "\n",
    "    res = [{\n",
    "        'sample_size': N,\n",
    "        'rep': i,\n",
    "        'sampling': len(sampling),\n",
    "        'transformation': transformation,\n",
    "        'tn': tn,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tp': tp,\n",
    "        'ypred':results_df['ypred'].sum(),\n",
    "        'recall': recall,\n",
    "        'precision': precision\n",
    "    }]\n",
    "    \n",
    "    results_df['FP'] = np.where((results_df.ytrue == 0) & (results_df.ypred == 1), 1, 0)\n",
    "    results_df.to_csv(f'/Users/zkarwowska/Desktop/EMBL_project/zeevi_dataset_v5/wilcoxon/{transformation}/wilcoxon_sampling_{N}_efs_3_rep_{i}_d_{len(sampling)}.csv')\n",
    "\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dac9cf-9afd-44c6-8eaa-b44dcd4ab709",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sampling = [[2, 5, 8, 12, 15, 19], [2, 10], [2, 6, 15, 19]]\n",
    "SampleSize = [10, 20, 30, 40, 50, 60]\n",
    "\n",
    "Wilcoxon_results_mean = pd.DataFrame()\n",
    "for transformation in ['clr', 'log_relab']:\n",
    "    for sampling in Sampling:\n",
    "        for N in SampleSize:\n",
    "            for i in range(1, 10):\n",
    "                df = run_wilcoxon_test(i, N, sampling, transformation)\n",
    "                Wilcoxon_results_mean = pd.concat([Wilcoxon_results_mean, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b800c6-892d-4a9e-a58e-bfc55cca82e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_G = Wilcoxon_results_mean.groupby(by = ['sample_size', 'transformation', 'sampling']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16733ce3-0567-44e1-97f7-24ba91681b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "for i, sampling in zip(range(3), (2, 4, 6)):\n",
    "    \n",
    "    df = Wilcoxon_results_mean[Wilcoxon_results_mean['sampling'] == sampling]\n",
    "    sns.lineplot(x = df.sample_size, y = df.precision, hue = df.transformation, ax=axes[i], lw=2)\n",
    "    axes[i].title.set_text(f'F={sampling}')\n",
    "    axes[i].set_ylim([-0.1, 1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e00b5-f94c-4944-8d3d-3d866d32848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "for i, sampling in zip(range(3), (2, 4, 6)):\n",
    "    \n",
    "    df = DF_G[DF_G['sampling'] == sampling]\n",
    "    sns.lineplot(x = df.sample_size, y = df.precision, hue = df.transformation, ax=axes[i], lw=2)\n",
    "    sns.scatterplot(x = df.sample_size, y = df.precision, hue = df.transformation, legend=None, ax=axes[i])\n",
    "    axes[i].title.set_text(f'F={sampling}')\n",
    "    axes[i].set_ylim([-0.1, 1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ffc80f-3c6b-4bf3-b327-4dbbae2304e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "for i, sampling in zip(range(3), (2, 4, 6)):\n",
    "    \n",
    "    df = DF_G[DF_G['sampling'] == sampling]\n",
    "    sns.lineplot(x = df.sample_size, y = df.recall, hue = df.transformation, ax=axes[i], lw=2)\n",
    "    sns.scatterplot(x = df.sample_size, y = df.recall, hue = df.transformation, legend=None, ax=axes[i])\n",
    "    axes[i].title.set_text(f'F={sampling}')\n",
    "    axes[i].set_ylim([-0.1, 1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf8f5b-edf7-4a29-b43b-d7b6d5c290f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF_G = Wilcoxon_results_mean.groupby(by = ['sample_size', 'transformation']).median().reset_index()\n",
    "sns.lineplot(x = DF_G.sample_size, y = DF_G.recall, hue = DF_G.transformation)\n",
    "sns.scatterplot(x = DF_G.sample_size, y = DF_G.recall, hue = DF_G.transformation, legend=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772920c9-e676-407a-a947-70631514fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wilcoxon_results_mean['setup'] = 'averaged_samples'\n",
    "Wilcoxon_results['setup'] = 'all_samples'\n",
    "\n",
    "DF = pd.concat([Wilcoxon_results_mean, Wilcoxon_results])\n",
    "DF_G = DF.groupby(by = ['sample_size', 'transformation', 'setup']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c8918-85b6-4f8b-b9e1-0f4a6fea705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5, 5))\n",
    "sns.lineplot(data=DF_G, x = 'sample_size', y = 'precision', hue = 'transformation', style = 'setup', lw=2)\n",
    "sns.scatterplot(data=DF_G, x = 'sample_size', y = 'precision', hue = 'transformation', style = 'setup', s=100, marker='s', legend=False)\n",
    "plt.title('COMPARISON BETWEEN AVERAGED AND ALL SAMPLES \\n F=3, EFS=3')\n",
    "plt.legend(edgecolor='w')\n",
    "plt.tight_layout()\n",
    "plt.savefig('setup_comparison.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b98ea-5678-4827-8602-bd8ee1c0884e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
